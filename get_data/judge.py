import time
import argparse
import json
import os
from tqdm import tqdm
import logging
from openai import OpenAI

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Constants
MAX_API_RETRY = 5

# Configure proxy (if needed)
os.environ["http_proxy"] = "http://localhost:7890"
os.environ["https_proxy"] = "http://localhost:7890"

def get_res(question: str, answer_a: str, answer_b: str, api_key: str, max_tokens: int = 4096):
    user_prompt = f'''
        You are a helpful assistant who reviews a debate between two other assistants in evaluating the quality of the outputs for a given instruction.The two assistants, Assistant (a) and Assistant (b), are given an instruction.
        Output (a) and Output (b) are generated by two different AI chatbots respectively.  Assistant (a) and Assistant (b) have conflicting evaluations. Your goal is to review their evaluations and give your final decision on which output is better.

        Here are some rules of the evaluation:
        1. You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.
        2. Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.
        3. You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should
        NOT affect your judgment, as Output (a) and Output (b) are **equally likely** to be the better.

        Output your final verdict by strictly following this format: "[[A]]" if Output (a) is better, "[[B]]" if Output (b) is better, and "[[C]]" for a tie.

        [Given instruction]
        {question}

        [The Start of Output (a)]
        {answer_a}
        [The End of Output (a)]

        [The Start of Output (b)]
        {answer_b}
        [The End of Output (b)]
        '''
    # API call logic with retries
    for i in range(MAX_API_RETRY):
        try:
            # Initialize OpenAI client
            client = OpenAI(api_key=api_key)

            # Make the API call
            response = client.chat.completions.create(
                model='gpt-4o',
                max_tokens=max_tokens,
                temperature=0.0,
                messages=[{
                    'role': 'user',
                    'content': user_prompt,
                }],
            )

            # Extract and log the content
            content = response.choices[0].message.content
            logger.info(content)
            return content

        except Exception as e:
            logger.error(f"Error occurred: {e}")
            time.sleep(20)

    logger.error(f"Failed after {MAX_API_RETRY} retries.")
    return 'error'
